[
  {
    "name": "list_tables_in_directory",
    "description": "List all parquet files in a directory with metadata including row count and column count",
    "function": null,
    "metadata": {
      "name": "list_tables_in_directory",
      "description": "List all parquet files in a directory with metadata",
      "requires": "duckdb, pathlib, json",
      "args": [
        "directory (str): Path to directory to search for parquet files"
      ],
      "returns": [
        "files_info (str): JSON string containing list of files with metadata"
      ]
    },
    "script_content": "```python\nimport json\nfrom pathlib import Path\n\ndef list_tables_in_directory(directory: str) -> str:\n    \"\"\"List all parquet files in a directory with metadata.\"\"\"\n    try:\n        import duckdb\n    except ImportError:\n        return json.dumps({\"error\": \"duckdb is required. Install it with: pip install duckdb\"})\n    \n    dir_path = Path(directory)\n    if not dir_path.exists():\n        raise FileNotFoundError(f\"Directory not found: {directory}\")\n\n    if not dir_path.is_dir():\n        raise ValueError(f\"Path is not a directory: {directory}\")\n\n    files_info = []\n    cwd = Path.cwd()\n    \n    for file_path in dir_path.glob(\"*.parquet\"):\n        file_path_str = str(file_path)\n        file_path_obj = Path(file_path_str)\n        if file_path_obj.is_absolute():\n            try:\n                file_path_str = str(file_path_obj.relative_to(cwd))\n            except ValueError:\n                file_path_str = str(file_path_obj)\n        \n        try:\n            conn = duckdb.connect(\":memory:\")\n            row_count_result = conn.execute(f\"SELECT COUNT(*) FROM read_parquet('{file_path_str}')\").fetchone()\n            if row_count_result is None:\n                raise RuntimeError(\"Failed to read row count\")\n            row_count = row_count_result[0]\n            \n            result = conn.execute(f\"SELECT * FROM read_parquet('{file_path_str}') LIMIT 0\")\n            column_count = len(result.description)\n            conn.close()\n\n            files_info.append({\n                \"filename\": file_path.name,\n                \"path\": str(file_path),\n                \"row_count\": row_count,\n                \"column_count\": column_count,\n            })\n        except Exception as e:\n            files_info.append({\n                \"filename\": file_path.name, \n                \"path\": str(file_path), \n                \"error\": str(e)\n            })\n\n    return json.dumps(files_info, ensure_ascii=False, indent=2)\n\n```",
    "created_at": "2025-11-17T11:51:03.229227",
    "usage_count": 0,
    "last_used": null
  },
  {
    "name": "get_schema",
    "description": "Get schema information of a parquet file including column names, types, and row count",
    "function": null,
    "metadata": {
      "name": "get_schema",
      "description": "Get schema information of a parquet file",
      "requires": "duckdb, pathlib, json",
      "args": [
        "parquet_file (str): Path to parquet file to inspect"
      ],
      "returns": [
        "schema_info (str): JSON string containing file metadata"
      ]
    },
    "script_content": "```python\nimport json\nfrom pathlib import Path\n\ndef get_schema(parquet_file: str) -> str:\n    \"\"\"Get schema information of a parquet file.\"\"\"\n    try:\n        import duckdb\n    except ImportError:\n        return json.dumps({\"error\": \"duckdb is required. Install it with: pip install duckdb\"})\n    \n    if not Path(parquet_file).exists():\n        raise FileNotFoundError(f\"Parquet file not found: {parquet_file}\")\n\n    conn = duckdb.connect(\":memory:\")\n    try:\n        cwd = Path.cwd()\n        parquet_file_obj = Path(parquet_file)\n        if parquet_file_obj.is_absolute():\n            try:\n                parquet_file = str(parquet_file_obj.relative_to(cwd))\n            except ValueError:\n                parquet_file = str(parquet_file_obj)\n\n        result = conn.execute(f\"SELECT * FROM read_parquet('{parquet_file}') LIMIT 0\")\n        schema = [{\"name\": desc[0], \"type\": str(desc[1])} for desc in result.description]\n\n        row_count_result = conn.execute(f\"SELECT COUNT(*) FROM read_parquet('{parquet_file}')\").fetchone()\n        if row_count_result is None:\n            raise RuntimeError(\"Failed to read row count\")\n        row_count = row_count_result[0]\n\n        schema_info = {\n            \"file\": parquet_file,\n            \"row_count\": row_count,\n            \"columns\": schema,\n        }\n\n        return json.dumps(schema_info, ensure_ascii=False, indent=2)\n\n    finally:\n        conn.close()\n\n```",
    "created_at": "2025-11-17T11:51:03.229242",
    "usage_count": 0,
    "last_used": null
  },
  {
    "name": "query_parquet_files",
    "description": "Query parquet files using SQL syntax for data analysis. Each file becomes a queryable table named after its filename",
    "function": null,
    "metadata": {
      "name": "query_parquet_files",
      "description": "Query parquet files using SQL syntax",
      "requires": "duckdb, pathlib, json, datetime",
      "args": [
        "parquet_files (Union[str, List[str]]): Path(s) to parquet file(s)",
        "query (str): SQL query to execute",
        "limit (int): Maximum records to return (default: 10)"
      ],
      "returns": [
        "result (str): JSON string of query results"
      ]
    },
    "script_content": "```python\nimport json\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Union, List\n\ndef query_parquet_files(parquet_files: Union[str, List[str]], query: str, limit: int = 10) -> str:\n    \"\"\"Query parquet files using SQL syntax.\"\"\"\n    try:\n        import duckdb\n    except ImportError:\n        return json.dumps({\"error\": \"duckdb is required. Install it with: pip install duckdb\"})\n    \n    if isinstance(parquet_files, str):\n        parquet_files = [parquet_files]\n\n    for file_path in parquet_files:\n        if not Path(file_path).exists():\n            raise FileNotFoundError(f\"Parquet file not found: {file_path}\")\n\n    conn = duckdb.connect(\":memory:\")\n    table_names = set()\n\n    try:\n        cwd = Path.cwd()\n        relative_parquet_files = []\n        for file_path in parquet_files:\n            file_path_obj = Path(file_path)\n            if file_path_obj.is_absolute():\n                try:\n                    file_path = str(file_path_obj.relative_to(cwd))\n                except ValueError:\n                    file_path = str(file_path_obj)\n            relative_parquet_files.append(file_path)\n        parquet_files = relative_parquet_files\n\n        for file_path in parquet_files:\n            base_name = Path(file_path).stem\n            table_name = base_name\n            counter = 1\n            while table_name in table_names:\n                table_name = f\"{base_name}_{counter}\"\n                counter += 1\n            table_names.add(table_name)\n            conn.execute(f\"CREATE VIEW {table_name} AS SELECT * FROM read_parquet('{file_path}')\")\n\n        result = conn.execute(query).fetchall()\n        columns = [desc[0] for desc in conn.description]\n\n        def serialize_datetime(obj):\n            if isinstance(obj, datetime):\n                return obj.isoformat()\n            elif isinstance(obj, dict):\n                return {key: serialize_datetime(value) for key, value in obj.items()}\n            elif isinstance(obj, list):\n                return [serialize_datetime(item) for item in obj]\n            else:\n                return obj\n\n        rows = [dict(zip(columns, row, strict=False)) for row in result]\n        serialized_rows = serialize_datetime(rows)\n\n        if len(serialized_rows) > limit:\n            serialized_rows = serialized_rows[:limit]\n\n        return json.dumps(serialized_rows, ensure_ascii=False, indent=2)\n\n    except Exception as e:\n        return json.dumps({\"error\": f\"Query failed: {str(e)}\", \"query\": query})\n    finally:\n        conn.close()\n\n```",
    "created_at": "2025-11-17T11:51:03.229247",
    "usage_count": 0,
    "last_used": null
  },
  {
    "name": "execute_code_in_virtual_environment",
    "description": "Executes a given snippet of Python code in a temporary, isolated virtual environment with a specific version of a library (e.g., pytorch, numpy) installed. It returns the standard output of the executed code.",
    "function": null,
    "metadata": {
      "name": "execute_code_in_virtual_environment",
      "description": "Executes a given snippet of Python code in a temporary, isolated virtual environment with a specific version of a library (e.g., pytorch, numpy) installed. It returns the standard output of the executed code.",
      "requires": "subprocess, sys, os, tempfile",
      "args": [
        "code_snippet (str): The Python code to execute.",
        "library_name (str): The name of the library to install (e.g., 'torch').",
        "library_version (str): The specific version of the library to install (e.g., '1.12.1')."
      ],
      "returns": [
        "result (str): The standard output from the executed code snippet."
      ]
    },
    "script_content": "```python\n# MCP Name: execute_code_in_virtual_environment\n# Description: Executes a given snippet of Python code in a temporary, isolated virtual environment with a specific version of a library (e.g., pytorch, numpy) installed. It returns the standard output of the executed code.\n# Arguments:\n#   code_snippet (str): The Python code to execute.\n#   library_name (str): The name of the library to install (e.g., 'torch').\n#   library_version (str): The specific version of the library to install (e.g., '1.12.1').\n# Returns:\n#   result (str): The standard output from the executed code snippet.\n# Requires: subprocess, sys, os, tempfile\n\nimport subprocess\nimport sys\nimport os\nimport tempfile\n\ndef execute_code_in_virtual_environment(code_snippet: str, library_name: str, library_version: str) -> str:\n    \"\"\"\n    Executes a given snippet of Python code in a temporary, isolated virtual environment\n    with a specific version of a library installed. It returns the standard output of the\n    executed code.\n\n    Args:\n        code_snippet (str): The Python code to execute.\n        library_name (str): The name of the library to install (e.g., 'torch').\n        library_version (str): The specific version of the library to install (e.g., '1.12.1').\n\n    Returns:\n        str: The standard output from the executed code snippet.\n    \"\"\"\n    try:\n        # Create a temporary directory which will be automatically cleaned up\n        with tempfile.TemporaryDirectory() as venv_dir:\n            # 1. Create the virtual environment\n            subprocess.run(\n                [sys.executable, \"-m\", \"venv\", venv_dir],\n                check=True,\n                capture_output=True\n            )\n\n            # 2. Determine platform-specific executable paths\n            if sys.platform == \"win32\":\n                python_executable = os.path.join(venv_dir, \"Scripts\", \"python.exe\")\n            else:\n                python_executable = os.path.join(venv_dir, \"bin\", \"python\")\n\n            # 3. Install the specified library version using the venv's pip\n            # Using --no-cache-dir to ensure the correct version is fetched every time.\n            # For torch, specifying the CPU index URL is more reliable for non-GPU environments.\n            install_command = [\n                python_executable, \"-m\", \"pip\", \"install\", f\"{library_name}=={library_version}\", \"--no-cache-dir\"\n            ]\n            if library_name.lower() == 'torch':\n                install_command.extend([\"--index-url\", \"https://download.pytorch.org/whl/cpu\"])\n\n            subprocess.run(\n                install_command,\n                check=True,\n                capture_output=True,\n                text=True\n            )\n\n            # 4. Execute the provided code snippet in the virtual environment\n            execution_result = subprocess.run(\n                [python_executable, \"-c\", code_snippet],\n                check=True,\n                capture_output=True,\n                text=True\n            )\n\n            # 5. Return the standard output, stripping any trailing whitespace\n            return execution_result.stdout.strip()\n\n    except subprocess.CalledProcessError as e:\n        # Provide detailed error information if any command fails\n        error_details = f\"Stderr: {e.stderr}\\nStdout: {e.stdout}\"\n        return f\"An error occurred in a subprocess: {e.cmd}. {error_details}\"\n    except Exception as e:\n        return f\"An unexpected error occurred: {str(e)}\"\n```",
    "created_at": "2025-07-29T04:26:50.709653",
    "usage_count": 5,
    "last_used": "2025-07-29T13:25:04.175625"
  },
  {
    "name": "python_interpreter",
    "description": "Executes a given Python script string. It can access variables provided in the context, such as the string array `arr`.",
    "function": null,
    "metadata": {
      "name": "python_interpreter",
      "description": "Executes a given Python script string. It can access variables provided in the context, such as the string array `arr`.",
      "requires": "sys, io",
      "args": [
        "script_string (str): The Python script to execute as a string.",
        "context_variables (dict): A dictionary of variables to be made available to the script's execution context. Keys are variable names (str), values are the variable's data."
      ],
      "returns": [
        "result (str): The captured standard output from the executed script."
      ]
    },
    "script_content": "```python\n# MCP Name: python_interpreter\n# Description: Executes a given Python script string. It can access variables provided in the context, such as the string array `arr`.\n# Arguments:\n#   script_string (str): The Python script to execute as a string.\n#   context_variables (dict): A dictionary of variables to be made available to the script's execution context. Keys are variable names (str), values are the variable's data.\n# Returns:\n#   result (str): The captured standard output from the executed script.\n# Requires: sys, io\n\nimport sys\nimport io\n\ndef python_interpreter(script_string: str, context_variables: dict):\n    \"\"\"\n    Executes a given Python script string and captures its standard output.\n\n    Args:\n        script_string (str): The Python script to execute as a string.\n        context_variables (dict): A dictionary of variables to be made available to the script's execution context. Keys are variable names (str), values are the variable's data.\n\n    Returns:\n        result (str): The captured standard output from the executed script, stripped of leading/trailing whitespace.\n    \"\"\"\n    # Create a string buffer to capture stdout\n    old_stdout = sys.stdout\n    redirected_output = sys.stdout = io.StringIO()\n\n    try:\n        # Execute the script. The context_variables are passed as the global scope.\n        exec(script_string, context_variables)\n        \n        # Restore the original stdout\n        sys.stdout = old_stdout\n        \n        # Get the captured output from the buffer and strip any extra whitespace/newlines\n        result = redirected_output.getvalue().strip()\n        \n        return result\n    except Exception as e:\n        # Ensure stdout is restored even if an error occurs\n        sys.stdout = old_stdout\n        return f\"Error executing script: {str(e)}\"\n\n```",
    "created_at": "2025-08-02T06:23:59.952751",
    "usage_count": 13,
    "last_used": "2025-08-02T14:06:16.818481"
  }
]